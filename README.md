# ğŸ¬ VIRAL VIDEO AUTO-GENERATOR

**à¸£à¸°à¸šà¸šà¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´à¸ªà¸³à¸«à¸£à¸±à¸šà¸ªà¸£à¹‰à¸²à¸‡à¸§à¸´à¸”à¸µà¹‚à¸­à¹„à¸§à¸£à¸±à¸¥à¸”à¹‰à¸§à¸¢ AI**

## ğŸ¯ à¸„à¸§à¸²à¸¡à¸ªà¸²à¸¡à¸²à¸£à¸–à¸«à¸¥à¸±à¸

âœ… **à¹à¸à¸°à¹€à¸ªà¸µà¸¢à¸‡** - à¹à¸›à¸¥à¸‡à¸§à¸´à¸”à¸µà¹‚à¸­à¹€à¸›à¹‡à¸™à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡ (Word-level Timestamps)  
âœ… **à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ AI** - à¸«à¸²à¸Šà¹ˆà¸§à¸‡ "Viral Moments" à¸—à¸µà¹ˆà¸™à¹ˆà¸²à¸ªà¸™à¹ƒà¸ˆ  
âœ… **à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¹ƒà¸šà¸«à¸™à¹‰à¸²** - Auto-reframe à¸§à¸´à¸”à¸µà¹‚à¸­à¹€à¸›à¹‡à¸™à¹à¸™à¸§à¸•à¸±à¹‰à¸‡ (9:16)  
âœ… **à¹€à¸£à¸™à¹€à¸”à¸­à¸£à¹Œà¸‚à¸±à¹‰à¸™à¸ªà¸¹à¸‡** - à¹ƒà¸ªà¹ˆà¸‹à¸±à¸šà¹„à¸•à¹€à¸•à¸´à¸¥à¹€à¸”à¹‰à¸‡à¹† à¸à¸£à¹‰à¸­à¸¡ animations  

---

## ğŸ—ï¸ à¸ªà¸–à¸²à¸›à¸±à¸•à¸¢à¸à¸£à¸£à¸¡ 4 Components

```
INPUT VIDEO (test.mp4)
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1ï¸âƒ£ AUDIO ENGINE (Whisper)            â”‚
â”‚    - à¹à¸à¸°à¹€à¸ªà¸µà¸¢à¸‡ â†’ à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡              â”‚
â”‚    - Word-level timestamps           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2ï¸âƒ£ CONTENT INTELLIGENCE (GPT)        â”‚
â”‚    - à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ transcript            â”‚
â”‚    - à¸«à¸² viral moments                â”‚
â”‚    - à¹ƒà¸«à¹‰ viral scores                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3ï¸âƒ£ VISION ENGINE (MediaPipe)         â”‚
â”‚    - à¸•à¸£à¸§à¸ˆà¸ˆà¸±à¸šà¹ƒà¸šà¸«à¸™à¹‰à¸²                   â”‚
â”‚    - à¸„à¸³à¸™à¸§à¸“ crop window 9:16          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4ï¸âƒ£ VIDEO RENDERER (MoviePy)          â”‚
â”‚    - à¸•à¸±à¸”/resize à¸§à¸´à¸”à¸µà¹‚à¸­               â”‚
â”‚    - à¹€à¸à¸´à¹ˆà¸¡à¸‹à¸±à¸šà¹„à¸•à¹€à¸•à¸´à¸¥                  â”‚
â”‚    - Render output files             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
OUTPUT: viral_output.mp4 + viral_9_16.mp4
```

---

## ğŸ“‹ à¹„à¸Ÿà¸¥à¹Œà¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™

| à¹„à¸Ÿà¸¥à¹Œ | à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™ | à¸„à¸³à¸­à¸˜à¸´à¸šà¸²à¸¢ |
|-----|--------|--------|
| `main_integrated.py` | Orchestrator | à¹€à¸£à¸µà¸¢à¸à¹ƒà¸Šà¹‰à¸—à¸±à¹‰à¸‡ 4 components |
| `audio_engine.py` | Component 1 | FFmpeg + Whisper |
| `content_intelligence.py` | Component 2 | OpenAI GPT API |
| `vision_engine.py` | Component 3 | MediaPipe face detection |
| `video_renderer.py` | Component 4 | MoviePy rendering |

---

## âš¡ Quick Start

### 1. à¸•à¸´à¸”à¸•à¸±à¹‰à¸‡ Dependencies
```bash
pip install -r requirements.txt
```

### 2. à¹ƒà¸ªà¹ˆà¹„à¸Ÿà¸¥à¹Œà¸§à¸´à¸”à¸µà¹‚à¸­
```bash
# Copy à¹„à¸Ÿà¸¥à¹Œà¸‚à¸­à¸‡à¸„à¸¸à¸“à¹€à¸‚à¹‰à¸² workspace
cp /path/to/your/video.mp4 c:\Webpedpok\test.mp4
```

### 3. à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² API Key (optional)
```bash
# Windows PowerShell:
$env:OPENAI_API_KEY = "your-api-key-here"

# Linux/macOS:
export OPENAI_API_KEY="your-api-key-here"
```

### 4. à¹€à¸£à¸µà¸¢à¸à¹ƒà¸Šà¹‰à¸‡à¸²à¸™
```bash
# à¹à¸šà¸šà¸‡à¹ˆà¸²à¸¢ (à¹ƒà¸Šà¹‰ default settings)
python main_integrated.py

# à¹à¸šà¸šà¸à¸³à¸«à¸™à¸”à¹€à¸­à¸‡
python main_integrated.py --input myvideo.mp4 --preset fast --device cuda
```

### 5. à¸£à¸­à¸ˆà¸™à¹€à¸ªà¸£à¹‡à¸ˆ
```
OUTPUT:
  âœ… output_viral.mp4 (à¸à¸±à¸šà¸‹à¸±à¸šà¹„à¸•à¹€à¸•à¸´à¸¥)
  âœ… output_viral_9_16.mp4 (à¹à¸™à¸§à¸•à¸±à¹‰à¸‡)
  âœ… analysis_report.json (à¸£à¸²à¸¢à¸‡à¸²à¸™)
```

---

## ğŸ›ï¸ Command-Line Options

```bash
python main_integrated.py [OPTIONS]

Options:
  --input FILE              Input video file (default: test.mp4)
  --output FILE             Output video file (default: output_viral.mp4)
  --model {tiny,base,small,medium,large,large-v3-turbo}
                           Whisper model size (default: large-v3-turbo)
  --device {cuda,cpu}      Processing device (default: cuda)
  --preset {ultrafast,fast,medium,slow}
                           Render quality (default: medium)
  --no-vision              Disable Vision component
  --no-9-16                Disable 9:16 format output
  --no-render              Analysis only (skip rendering)

Examples:
  python main_integrated.py --input myvideo.mp4 --preset fast
  python main_integrated.py --model small --device cpu
  python main_integrated.py --no-vision --no-9-16
```

---

## ğŸ“Š Output Files

### 1. `output_viral.mp4`
- à¸§à¸´à¸”à¸µà¹‚à¸­à¹€à¸•à¹‡à¸¡à¸„à¸§à¸²à¸¡à¸ªà¸¹à¸‡à¸•à¹‰à¸™à¸‰à¸šà¸±à¸š
- à¸¡à¸µ subtitles à¸•à¸²à¸¡à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡
- Format: 16:9 (landscape)

### 2. `output_viral_9_16.mp4`
- à¸§à¸´à¸”à¸µà¹‚à¸­à¹à¸™à¸§à¸•à¸±à¹‰à¸‡ (TikTok-style)
- Crop à¸•à¸²à¸¡à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¹ƒà¸šà¸«à¸™à¹‰à¸²
- Format: 9:16 (portrait)

### 3. `analysis_report.json`
```json
{
  "input_video": "test.mp4",
  "transcription": {
    "language": "th",
    "segments_count": 42
  },
  "moments": [
    {
      "start": 15.5,
      "end": 45.0,
      "headline": "à¸Šà¹ˆà¸§à¸‡à¸—à¸µà¹ˆà¸•à¸¥à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸”",
      "viral_score": 92,
      "reason": "à¸•à¸¥à¸à¸ªà¸™à¸¸à¸ relatable"
    },
    ...
  ],
  "outputs": {
    "main_video": "output_viral.mp4",
    "vertical_video": "output_viral_9_16.mp4"
  }
}
```

---

## ğŸ”§ Configuration

### à¸›à¸£à¸±à¸šà¹à¸•à¹ˆà¸‡à¹ƒà¸™à¹„à¸Ÿà¸¥à¹Œ `main_integrated.py` (Class: Config)

```python
class Config:
    # Input/Output
    INPUT_VIDEO = "test.mp4"
    OUTPUT_VIDEO = "output_viral.mp4"
    
    # Model Settings
    WHISPER_MODEL = "large-v3-turbo"  # à¹ƒà¸«à¸à¹ˆà¹à¸¡à¹ˆà¸™à¸¢à¸³ (à¸Šà¹‰à¸²)
                                       # à¸«à¸£à¸·à¸­ "base" (à¹€à¸£à¹‡à¸§)
    DEVICE = "cuda"                   # cuda à¸«à¸£à¸·à¸­ cpu
    
    # Components
    ENABLE_VISION = True              # auto-reframe
    ENABLE_9_16_FORMAT = True         # à¸ªà¸£à¹‰à¸²à¸‡à¹à¸™à¸§à¸•à¸±à¹‰à¸‡
    RENDER_OUTPUT = True              # render output
    
    # Render Quality
    OUTPUT_FPS = 30
    PRESET = "medium"  # ultrafast < fast < medium < slow
```

---

## âš ï¸ Troubleshooting

### 1. "FFmpeg not found"
```bash
# Windows:
choco install ffmpeg

# macOS:
brew install ffmpeg

# Linux:
sudo apt-get install ffmpeg
```

### 2. "CUDA not available" (wants GPU acceleration)
```bash
# Check CUDA:
python -c "import torch; print(torch.cuda.is_available())"

# If False, install PyTorch with CUDA:
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### 3. "OpenAI API error"
- à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š API key: `echo $OPENAI_API_KEY`
- à¸«à¸£à¸·à¸­ run without API (à¹ƒà¸Šà¹‰ Mock analysis): à¸›à¸¥à¹ˆà¸­à¸¢à¹„à¸§à¹‰à¸§à¹ˆà¸²à¸‡

### 4. "Out of memory"
- à¸¥à¸”à¸‚à¸™à¸²à¸” model: `--model small`
- à¹ƒà¸Šà¹‰ CPU: `--device cpu`
- à¸¥à¸”à¸„à¸§à¸²à¸¡à¸ˆà¸£à¸´à¸‡/à¸„à¸§à¸²à¸¡à¸¢à¸²à¸§à¸§à¸´à¸”à¸µà¹‚à¸­

### 5. Rendering takes too long
- à¹ƒà¸Šà¹‰ fast preset: `--preset fast`
- à¸¥à¸”à¸„à¸§à¸²à¸¡à¸«à¸¥à¸²à¸à¸«à¸¥à¸²à¸¢à¸‚à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
- à¸›à¸´à¸” Vision: `--no-vision`

---

## ğŸ“ Understanding the Components

### 1ï¸âƒ£ AudioEngine
```python
from audio_engine import AudioEngine

engine = AudioEngine(model_size="large-v3-turbo", device="cuda")
audio_path = engine.convert_to_wav("video.mp4")
segments, info = engine.transcribe(audio_path, word_timestamps=True)

# segments = [
#   {id: 0, seek: 0, start: 0.5, end: 5.2, text: "à¸ªà¸§à¸±à¸ªà¸”à¸µ...", 
#    words: [{word: "à¸ªà¸§à¸±à¸ªà¸”à¸µ", start: 0.5, end: 1.2}, ...]},
#   ...
# ]
```

### 2ï¸âƒ£ ContentIntelligence
```python
from content_intelligence import ContentIntelligence

ci = ContentIntelligence(api_key="sk-...")
moments = ci.find_best_moments(full_transcript, num_moments=3)

# moments = [
#   {start: 15.5, end: 45.0, headline: "...", viral_score: 92, reason: "..."},
#   ...
# ]
```

### 3ï¸âƒ£ VisionEngine
```python
from vision_engine import VisionEngine

vision = VisionEngine()
x_center, y_center, detected = vision.get_face_center(frame)

# Auto-crop 9:16 format
cropped_frame = vision.crop_frame_9_16(frame, x_center, y_center)

# Analyze whole video
analysis = vision.process_video_samples("video.mp4", sample_frames=5)
```

### 4ï¸âƒ£ VideoRenderer
```python
from video_renderer import VideoRenderer

renderer = VideoRenderer(fontsize=80, color="yellow")

# Render with subtitles
renderer.render_viral_clip(
    input_video="video.mp4",
    output_name="output.mp4",
    moment_segments=moments,
    word_subtitles=word_list
)

# Render 9:16 format
renderer.render_9_16_format(
    input_video="video.mp4",
    output_name="output_9_16.mp4",
    face_tracking_data=vision_analysis
)
```

---

## ğŸ“ˆ Performance

| Model Size | Speed | Accuracy | VRAM | Best For |
|-----------|-------|----------|------|----------|
| tiny | âš¡âš¡âš¡âš¡ | 60% | 1GB | Quick test |
| base | âš¡âš¡âš¡ | 75% | 2GB | Fast preview |
| small | âš¡âš¡ | 85% | 3GB | Balanced |
| medium | âš¡ | 92% | 5GB | Good quality |
| large | ğŸ¢ | 97% | 10GB | Best quality |
| large-v3-turbo | âš¡ | 95% | 8GB | **Recommended** |

---

## ğŸš€ Advanced Usage

### Process Multiple Videos
```bash
# Batch processing
for video in *.mp4; do
  python main_integrated.py --input "$video" --output "viral_${video}"
  echo "âœ… Processed $video"
done
```

### Analysis Only (No Rendering)
```bash
python main_integrated.py --no-render
# Output: analysis_report.json only
```

### Custom Components
```python
from main_integrated import ViralVideoGenerator, Config

config = Config()
config.INPUT_VIDEO = "custom.mp4"
config.WHISPER_MODEL = "small"
config.PRESET = "ultrafast"

generator = ViralVideoGenerator(config)
generator.run()
```

---

## ğŸ“ License & Attribution

- **Whisper**: OpenAI
- **MoviePy**: Zulko
- **MediaPipe**: Google
- **OpenAI API**: OpenAI

---

## ğŸ¤ Support & Issues

If you encounter issues:

1. Check the [Troubleshooting](#troubleshooting-) section
2. Verify all dependencies: `pip list`
3. Check logs in console output
4. Try with `--device cpu` and `--preset fast`

---

## ğŸ“š Next Steps

1. **Fine-tune prompts** in `content_intelligence.py` for better moment detection
2. **Customize subtitles** style (color, font, position) in `video_renderer.py`
3. **Add effects** using MoviePy's fx library
4. **Integrate other LLMs** (Llama, Claude, etc.)
5. **Deploy as API** using FastAPI/Flask

Happy rendering! ğŸ¬âœ¨
