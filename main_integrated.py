#!/usr/bin/env python3
"""
=========================================
üé¨ VIRAL VIDEO AUTO-GENERATOR SYSTEM üé¨
=========================================

4-Component Architecture:
1. AudioEngine      - ‡πÅ‡∏Å‡∏∞‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (Whisper)
2. ContentIntelligence - ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏´‡∏≤ viral moments (GPT)
3. VisionEngine     - auto-reframe ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ (MediaPipe)
4. VideoRenderer    - ‡πÄ‡∏£‡∏ô‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏≠‡∏≠‡∏Å‡∏°‡∏≤ (MoviePy)

Workflow: Test.mp4 ‚Üí Audio Extract ‚Üí Transcribe ‚Üí Analyze ‚Üí Vision ‚Üí Render ‚Üí viral_output.mp4

BONUS: Support YouTube URLs - Auto-download & process!
"""

import os
import time
import argparse
import json
import subprocess
import sys
from pathlib import Path
from urllib.parse import urlparse

# Import components
from audio_engine import AudioEngine
from content_intelligence import ContentIntelligence
from vision_engine import VisionEngine
from video_renderer import VideoRenderer

# ==========================================
# üé• YOUTUBE HELPER FUNCTIONS
# ==========================================
def is_youtube_url(url: str) -> bool:
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô YouTube URL ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
    youtube_domains = ['youtube.com', 'youtu.be', 'm.youtube.com', 'www.youtube.com']
    try:
        parsed_url = urlparse(url)
        return any(domain in parsed_url.netloc for domain in youtube_domains)
    except:
        return False

def download_youtube_video(youtube_url: str, output_file: str = "youtube_download.mp4") -> str:
    """‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å YouTube
    
    Args:
        youtube_url: YouTube URL
        output_file: ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏≠‡∏≤‡∏ï‡πå‡∏û‡∏∏‡∏ï
        
    Returns:
        str: path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î ‡∏´‡∏£‡∏∑‡∏≠ None
    """
    print("\nüì• ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å YouTube...")
    print(f"   URL: {youtube_url}")
    print("   ‚è≥ ‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà...\n")
    
    try:
        # ‡πÉ‡∏ä‡πâ python -m yt_dlp ‡∏Å‡∏±‡∏ö devnull ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡πá‡∏ß
        cmd = [
            sys.executable,
            "-m", "yt_dlp",
            "-f", "best[height<=720]/best",
            "-o", output_file,
            "--quiet",  # ‡∏•‡∏î‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á log
            youtube_url
        ]
        
        result = subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, timeout=300)
        
        if os.path.exists(output_file):
            file_size_mb = os.path.getsize(output_file) / (1024 * 1024)
            file_duration_info = ""
            try:
                import mediainfo
                file_duration_info = " (‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤)"
            except:
                pass
            
            print(f"   ‚úÖ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ({file_size_mb:.1f} MB){file_duration_info}")
            return output_file
        else:
            print(f"   ‚ùå ‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á")
            return None
            
    except subprocess.TimeoutExpired:
        print(f"   ‚è±Ô∏è  ‡∏´‡∏°‡∏î‡πÄ‡∏ß‡∏•‡∏≤ (>5 ‡∏ô‡∏≤‡∏ó‡∏µ) - ‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏≠‡∏≤‡∏à‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ")
        print("   üí° ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ: --model tiny ‡∏´‡∏£‡∏∑‡∏≠ --preset ultrafast")
        return None
    except Exception as e:
        print(f"   ‚ùå yt-dlp error: {str(e)[:100]}")
        print("   üí° ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö:")
        print("      - URL ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏´‡∏°")
        print("      - Internet connection OK?")
        print("      - ‡∏•‡∏≠‡∏á: pip install --upgrade yt-dlp")
        return None

# ==========================================
# ‚öôÔ∏è CONFIGURATION
# ==========================================
class Config:
    # Input/Output
    INPUT_VIDEO = "test.mp4"
    OUTPUT_VIDEO = "output_viral.mp4"
    OUTPUT_VIDEO_9_16 = "output_viral_9_16.mp4"
    OUTPUT_REPORT = "analysis_report.json"
    TEMP_AUDIO = "temp_audio.wav"
    
    # Audio Engine
    WHISPER_MODEL = "large-v3-turbo"
    DEVICE = "cuda"  # ‡∏´‡∏£‡∏∑‡∏≠ "cpu"
    
    # Content Intelligence
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", None)
    CONTENT_ANALYSIS_NUM = 3  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô moments ‡∏ó‡∏µ‡πà‡∏°‡∏≠‡∏á‡∏´‡∏≤
    
    # Vision Engine
    FACE_CONFIDENCE = 0.5
    
    # Video Rendering
    OUTPUT_FPS = 30
    VIDEO_CODEC = "libx264"
    PRESET = "medium"  # ultrafast, fast, medium, slow
    
    # Features
    ENABLE_VISION = True
    ENABLE_9_16_FORMAT = True
    RENDER_OUTPUT = True


# ==========================================
# üöÄ MAIN ORCHESTRATOR
# ==========================================
class ViralVideoGenerator:
    """Main orchestrator ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ô‡∏ó‡∏≥‡∏á‡∏≤‡∏ô 4 components"""
    
    def __init__(self, config=Config):
        self.config = config
        self.audio_engine = None
        self.content_intelligence = None
        self.vision_engine = None
        self.video_renderer = None
        self.segments = None
        self.info = None
        self.moments = None
        self.vision_data = None
        
        print("\n" + "="*60)
        print("üé¨ VIRAL VIDEO AUTO-GENERATOR SYSTEM üé¨".center(60))
        print("="*60 + "\n")
    
    def initialize_components(self):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á instances ‡∏Ç‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á 4 components"""
        print("üì¶ INITIALIZATION PHASE\n")
        print("-" * 60)
        
        try:
            # 1. AudioEngine
            import torch
            device = "cuda" if torch.cuda.is_available() else "cpu"
            self.audio_engine = AudioEngine(
                model_size=self.config.WHISPER_MODEL,
                device=device
            )
            print()
            
            # 2. ContentIntelligence
            self.content_intelligence = ContentIntelligence(
                api_key=self.config.OPENAI_API_KEY
            )
            print()
            
            # 3. VisionEngine (optional)
            if self.config.ENABLE_VISION:
                try:
                    self.vision_engine = VisionEngine(
                        confidence=self.config.FACE_CONFIDENCE
                    )
                    print()
                except ImportError:
                    print("‚ö†Ô∏è  Vision disabled (MediaPipe not installed)\n")
                    self.config.ENABLE_VISION = False
            
            # 4. VideoRenderer
            imagemagick_path = None
            if os.name != 'nt':  # Non-Windows
                imagemagick_path = "/usr/bin/convert"  # Linux standard path
            
            self.video_renderer = VideoRenderer(
                imagemagick_path=imagemagick_path,
                font="Arial-Bold",
                fontsize=80,
                color="yellow"
            )
            print()
            
            print("‚úÖ All components initialized!\n")
            return True
            
        except Exception as e:
            print(f"‚ùå Initialization error: {e}")
            return False
    
    def run_pipeline(self):
        """‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ pipeline ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö"""
        print("="*60)
        print("PIPELINE EXECUTION\n")
        print("-" * 60)
        
        # Step 1: Extract & Transcribe
        if not self._step_1_audio_processing():
            return False
        
        # Step 2: Content Analysis
        if not self._step_2_content_analysis():
            return False
        
        # Step 3: Vision Processing
        if self.config.ENABLE_VISION and not self._step_3_vision_processing():
            print("‚ö†Ô∏è  Vision processing skipped\n")
        
        # Step 4: Render Output
        if self.config.RENDER_OUTPUT and not self._step_4_rendering():
            return False
        
        return True
    
    def _step_1_audio_processing(self):
        """Step 1: Audio Extraction & Transcription"""
        print("\nüìã STEP 1: AUDIO PROCESSING")
        print("-" * 60)
        
        try:
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï
            if not os.path.exists(self.config.INPUT_VIDEO):
                print(f"‚ùå ‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏û‡∏ö: {self.config.INPUT_VIDEO}")
                return False
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô WAV
            audio_path = self.audio_engine.convert_to_wav(
                self.config.INPUT_VIDEO,
                self.config.TEMP_AUDIO
            )
            
            # ‡πÅ‡∏Å‡∏∞‡πÄ‡∏™‡∏µ‡∏¢‡∏á
            start_time = time.time()
            self.segments, self.info = self.audio_engine.transcribe(
                audio_path,
                word_timestamps=True
            )
            elapsed = time.time() - start_time
            
            print(f"\nüìä Transcription Summary:")
            print(f"   Language: {self.info.language}")
            print(f"   Duration: {elapsed:.2f}s")
            print(f"   Segments: {len(self.segments)}")
            
            # ‡πÅ‡∏™‡∏î‡∏á preview (first 3 segments)
            print(f"\nüìù Preview (first 3 segments):")
            for i, seg in enumerate(self.segments[:3]):
                print(f"   [{seg.start:.2f}s - {seg.end:.2f}s] {seg.text[:50]}...")
            
            # ‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
            if os.path.exists(audio_path):
                os.remove(audio_path)
            
            return True
            
        except Exception as e:
            print(f"‚ùå Error in audio processing: {e}")
            return False
    
    def _step_2_content_analysis(self):
        """Step 2: Content Intelligence Analysis"""
        print("\nüìã STEP 2: CONTENT ANALYSIS")
        print("-" * 60)
        
        try:
            if not self.segments:
                print("‚ùå No transcript data from Step 1")
                return False
            
            # ‡∏£‡∏ß‡∏° transcript
            full_transcript = " ".join([seg.text for seg in self.segments])
            
            # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
            self.moments = self.content_intelligence.find_best_moments(
                transcript_text=full_transcript,
                num_moments=self.config.CONTENT_ANALYSIS_NUM
            )
            
            print(f"\nüìä Analysis Results:")
            print(f"   Found {len(self.moments)} viral moments\n")
            
            for i, moment in enumerate(self.moments, 1):
                print(f"   Moment {i}:")
                print(f"      Time: {moment.get('start'):.2f}s - {moment.get('end'):.2f}s")
                print(f"      Headline: {moment.get('headline', 'N/A')}")
                print(f"      Viral Score: {moment.get('viral_score', 0)}/100")
                if 'reason' in moment:
                    print(f"      Reason: {moment.get('reason')[:60]}...")
                print()
            
            return True
            
        except Exception as e:
            print(f"‚ùå Error in content analysis: {e}")
            return False
    
    def _step_3_vision_processing(self):
        """Step 3: Vision Engine Processing"""
        print("\nüìã STEP 3: VISION PROCESSING")
        print("-" * 60)
        
        try:
            if not self.vision_engine:
                print("‚ö†Ô∏è  Vision Engine not available")
                return False
            
            self.vision_data = self.vision_engine.process_video_samples(
                self.config.INPUT_VIDEO,
                sample_frames=5
            )
            
            print(f"\nüìä Vision Analysis Results:")
            print(f"   Face detected in: {self.vision_data['detected_count']} / {len(self.vision_data['face_positions'])} frames")
            print(f"   Detection rate: {100 * self.vision_data['detected_count'] / max(1, len(self.vision_data['face_positions'])):.1f}%")
            
            return True
            
        except Exception as e:
            print(f"‚ö†Ô∏è  Vision processing error: {e}")
            return False
    
    def _step_4_rendering(self):
        """Step 4: Video Rendering"""
        print("\nüìã STEP 4: VIDEO RENDERING")
        print("-" * 60)
        
        try:
            # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° subtitles ‡∏à‡∏≤‡∏Å segments
            word_subtitles = []
            for segment in self.segments:
                if hasattr(segment, 'words'):
                    for word in segment.words:
                        word_subtitles.append({
                            "word": word.word.strip(),
                            "start": word.start,
                            "end": word.end
                        })
            
            # Render main output
            print(f"\nüé¨ Rendering main output. It may take a while...")
            self.video_renderer.render_viral_clip(
                input_video=self.config.INPUT_VIDEO,
                output_name=self.config.OUTPUT_VIDEO,
                moment_segments=self.moments or [],
                word_subtitles=word_subtitles if word_subtitles else None,
                fps=self.config.OUTPUT_FPS,
                codec=self.config.VIDEO_CODEC,
                preset=self.config.PRESET
            )
            
            # Render 9:16 format (optional)
            if self.config.ENABLE_9_16_FORMAT:
                print(f"\nüé¨ Rendering 9:16 format...")
                self.video_renderer.render_9_16_format(
                    input_video=self.config.INPUT_VIDEO,
                    output_name=self.config.OUTPUT_VIDEO_9_16,
                    face_tracking_data=self.vision_data,
                    word_subtitles=word_subtitles if word_subtitles else None,
                    fps=self.config.OUTPUT_FPS
                )
            
            return True
            
        except Exception as e:
            print(f"‚ùå Rendering error: {e}")
            return False
    
    def save_report(self):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏õ‡πá‡∏ô JSON"""
        report = {
            "input_video": self.config.INPUT_VIDEO,
            "transcription": {
                "language": self.info.language if self.info else "unknown",
                "segments_count": len(self.segments) if self.segments else 0,
            },
            "moments": self.moments or [],
            "vision": self.vision_data or {},
            "outputs": {
                "main_video": self.config.OUTPUT_VIDEO,
                "vertical_video": self.config.OUTPUT_VIDEO_9_16 if self.config.ENABLE_9_16_FORMAT else None,
            }
        }
        
        with open(self.config.OUTPUT_REPORT, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"üìÑ Report saved: {self.config.OUTPUT_REPORT}")
    
    def run(self):
        """‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ pipeline ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
        start_time = time.time()
        
        # Initialize
        if not self.initialize_components():
            print("\n‚ùå Failed to initialize components")
            return False
        
        # Run pipeline
        if not self.run_pipeline():
            print("\n‚ùå Pipeline failed")
            return False
        
        # Save report
        self.save_report()
        
        # Summary
        elapsed = time.time() - start_time
        print("\n" + "="*60)
        print("‚úÖ PIPELINE COMPLETE!".center(60))
        print("="*60)
        print(f"\nTotal time: {elapsed:.1f}s")
        print(f"\nüìÅ Outputs:")
        print(f"   - {self.config.OUTPUT_VIDEO}")
        if self.config.ENABLE_9_16_FORMAT:
            print(f"   - {self.config.OUTPUT_VIDEO_9_16}")
        print(f"   - {self.config.OUTPUT_REPORT}")
        print()
        
        return True


# ==========================================
# üéØ MAIN ENTRY POINT
# ==========================================
def main():
    parser = argparse.ArgumentParser(
        description="üé¨ Viral Video Auto-Generator (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö YouTube!)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python main_integrated.py --input myvideo.mp4 --output result.mp4
  python main_integrated.py --input "https://www.youtube.com/watch?v=..." --output result.mp4
  python main_integrated.py --input test.mp4 --no-vision
  python main_integrated.py --preset fast --device cpu
        """
    )
    
    parser.add_argument("--input", default="test.mp4", help="Input video file ‡∏´‡∏£‡∏∑‡∏≠ YouTube URL")
    parser.add_argument("--output", default="output_viral.mp4", help="Output video file")
    parser.add_argument("--model", default="large-v3-turbo", help="Whisper model size")
    parser.add_argument("--device", default="cuda", help="Device: cuda or cpu")
    parser.add_argument("--preset", default="medium", help="Render preset: ultrafast, fast, medium, slow")
    parser.add_argument("--no-vision", action="store_true", help="Disable Vision component")
    parser.add_argument("--no-9-16", action="store_true", help="Disable 9:16 format")
    parser.add_argument("--no-render", action="store_true", help="Skip rendering (analysis only)")
    
    args = parser.parse_args()
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î YouTube video ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á
    input_file = args.input
    
    if is_youtube_url(args.input):
        print("\nüé• ‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö YouTube URL - ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î...")
        downloaded_file = download_youtube_video(args.input, "youtube_download.mp4")
        
        if downloaded_file:
            input_file = downloaded_file
            print(f"‚úÖ ‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î: {input_file}\n")
        else:
            print("‚ùå ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î YouTube ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß")
            return 1
    
    # Apply arguments to config
    config = Config()
    config.INPUT_VIDEO = input_file
    config.OUTPUT_VIDEO = args.output
    config.WHISPER_MODEL = args.model
    config.DEVICE = args.device
    config.PRESET = args.preset
    config.ENABLE_VISION = not args.no_vision
    config.ENABLE_9_16_FORMAT = not args.no_9_16
    config.RENDER_OUTPUT = not args.no_render
    
    # Run generator
    generator = ViralVideoGenerator(config)
    success = generator.run()
    
    return 0 if success else 1


if __name__ == "__main__":
    import sys
    sys.exit(main())
