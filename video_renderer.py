<<<<<<< HEAD
=======
<<<<<<< HEAD
# -*- coding: utf-8 -*-
import os
from typing import List, Dict, Tuple, Optional

# Set FFmpeg path
FFMPEG_PATH = r"C:\ffmpeg\bin\ffmpeg.exe"
if os.path.exists(FFMPEG_PATH):
    os.environ['FFMPEG_BINARY'] = FFMPEG_PATH

# Suppress imageio ffmpeg download
import imageio
imageio.plugins.ffmpeg.FFMPEG_BINARY = FFMPEG_PATH

try:
    from moviepy.editor import VideoFileClip, TextClip, CompositeVideoClip, vfx
except (ImportError, RuntimeError):
    # Fallback for moviepy 2.x
    from moviepy.video.io.VideoFileClip import VideoFileClip
    from moviepy.video.VideoClip import TextClip
    from moviepy.video.compositing.CompositeVideoClip import CompositeVideoClip
    import moviepy.video.fx as vfx

try:
    from moviepy.config import change_settings
    if os.path.exists(FFMPEG_PATH):
        change_settings({"FFMPEG_BINARY": FFMPEG_PATH})
except ImportError:
    def change_settings(d): pass  # Dummy function
=======
>>>>>>> SIJN
import os
from typing import List, Dict, Tuple, Optional
from moviepy.editor import VideoFileClip, TextClip, CompositeVideoClip, vfx
from moviepy.config import change_settings
<<<<<<< HEAD
=======
>>>>>>> aa72dfb (Initial project setup: WebPedPok YouTube video analysis and content intelligence system)
>>>>>>> SIJN

class VideoRenderer:
    """Component 4: Video Rendering Engine (MoviePy)
    
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô: ‡πÄ‡∏£‡∏ô‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ ‡πÇ‡∏î‡∏¢‡πÉ‡∏™‡πà:
    - ‡∏ã‡∏±‡∏ö‡πÑ‡∏ï‡πÄ‡∏ï‡∏¥‡∏•‡πÄ‡∏î‡πâ‡∏á‡πÜ (Bouncy subtitles)
    - ‡∏ï‡∏±‡∏î segment ‡∏ó‡∏µ‡πà AI ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
    - Auto-reframe ‡πÄ‡∏õ‡πá‡∏ô 9:16 ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    """
    
    def __init__(
        self,
        imagemagick_path: Optional[str] = None,
        font: str = "Arial-Bold",
        fontsize: int = 80,
        color: str = "yellow",
        stroke_color: str = "black",
        stroke_width: int = 2
    ):
        """
        Args:
            imagemagick_path: ‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á ImageMagick (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö rendering text ‡∏ö‡∏ô macOS)
            font: Font ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ (‡πÄ‡∏ä‡πà‡∏ô Arial-Bold, Courier)
            fontsize: ‡∏Ç‡∏ô‡∏≤‡∏î‡∏ü‡∏≠‡∏ô‡∏ï‡πå
            color: ‡∏™‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (yellow, white, etc.)
            stroke_color: ‡∏™‡∏µ‡∏Ç‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            stroke_width: ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏ô‡∏≤‡∏Ç‡∏≠‡∏á‡∏Ç‡∏≠‡∏ö
        """
        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ ImageMagick ‡∏ñ‡πâ‡∏≤‡∏£‡∏∞‡∏ö‡∏∏ (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö macOS/Linux)
        if imagemagick_path and os.path.exists(imagemagick_path):
            change_settings({"IMAGEMAGICK_BINARY": imagemagick_path})
            print(f"üñºÔ∏è  ImageMagick: {imagemagick_path}")
        
        self.font = font
        self.fontsize = fontsize
        self.color = color
        self.stroke_color = stroke_color
        self.stroke_width = stroke_width
        
        print(f"üîß ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á VideoRenderer...")
        print(f"   - Font: {self.font}")
        print(f"   - Size: {self.fontsize}px")
        print(f"   - Color: {self.color}")
        print(f"   ‚úÖ MoviePy Ready")
    
    def create_subtitle_clip(
        self,
        text: str,
        start_time: float,
        duration: float,
        position: Tuple[str, str] = ('center', 'bottom'),
        with_animation: bool = True
    ) -> TextClip:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á subtitle clip ‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß ‡∏û‡∏£‡πâ‡∏≠‡∏° animation
        
        Args:
            text: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á
            start_time: ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏° (‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)
            duration: ‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤ (‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)
            position: ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á ('center', 'bottom') ‡∏´‡∏£‡∏∑‡∏≠ ('left', 'top') ‡∏Ø‡∏•‡∏Ø
            with_animation: ‡πÉ‡∏ä‡πâ animation ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            
        Returns:
            TextClip: subtitle clip ‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ
        """
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á TextClip
        txt_clip = TextClip(
            text,
            fontsize=self.fontsize,
            color=self.color,
            font=self.font,
            stroke_color=self.stroke_color,
            stroke_width=self.stroke_width,
            method='label'
        )
        
        # ‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏ß‡∏•‡∏≤
        txt_clip = txt_clip.set_start(start_time).set_duration(max(0.1, duration))
        
        # ‡∏ï‡∏±‡πâ‡∏á‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á
        txt_clip = txt_clip.set_position(position)
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° animation ‡∏ñ‡πâ‡∏≤‡∏Å‡∏≥‡∏´‡∏ô‡∏î
        if with_animation:
            # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: Scale up ‡πÅ‡∏•‡πâ‡∏ß down (bounce effect)
            txt_clip = txt_clip.fx(vfx.grow, duration=duration * 0.1)
        
        return txt_clip
    
    def render_viral_clip(
        self,
        input_video: str,
        output_name: str,
        moment_segments: List[Dict],
        word_subtitles: Optional[List[Dict]] = None,
        fps: int = 30,
        codec: str = "libx264",
        preset: str = "medium"
    ) -> str:
        """‡πÄ‡∏£‡∏ô‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ viral clip ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
        
        Args:
            input_video: ‡πÑ‡∏ü‡∏•‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï
            output_name: ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏≠‡∏≤‡∏ï‡πå‡∏û‡∏∏‡∏ï
            moment_segments: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ moment segments (start, end, headline, etc.)
            word_subtitles: subtitle ‡∏ó‡∏µ‡∏•‡∏∞‡∏Ñ‡∏≥ (optional) - format: 
                            [{"word": "...", "start": 10.5, "end": 11.0}, ...]
            fps: Frames per second
            codec: video codec (libx264, libx265, etc.)
            preset: quality preset (ultrafast, fast, medium, slow)
            
        Returns:
            str: ‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏≠‡∏≤‡∏ï‡πå‡∏û‡∏∏‡∏ï
        """
        print(f"üé¨ 5. ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏ô‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏≠‡∏≠‡∏Å‡∏°‡∏≤...")
        print(f"   Input: {input_video}")
        print(f"   Output: {output_name}")
        
        # ‡πÇ‡∏´‡∏•‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
        video = VideoFileClip(input_video)
        original_fps = video.fps
        original_duration = video.duration
        
        print(f"   - Duration: {original_duration:.1f}s")
        print(f"   - FPS: {original_fps:.1f}")
        print(f"   - Codec: {codec}")
        
        # ‡πÄ‡∏Å‡πá‡∏ö list ‡∏Ç‡∏≠‡∏á text clips
        text_clips = []
        
        # ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏ï‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏á moment ‡∏ó‡∏µ‡πà AI ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
        # ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏Ç‡πâ‡∏≤‡∏° (‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î)
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° word subtitles
        if word_subtitles:
            print(f"   üìù ‡πÄ‡∏û‡∏¥‡πà‡∏° {len(word_subtitles)} subtitle...")
            for subtitle_data in word_subtitles:
                word = subtitle_data.get("word", "")
                start = subtitle_data.get("start", 0)
                end = subtitle_data.get("end", 0)
                duration = max(0.1, end - start)
                
                try:
                    txt_clip = self.create_subtitle_clip(
                        text=word.upper(),
                        start_time=start,
                        duration=duration,
                        position=('center', 'center'),
                        with_animation=True
                    )
                    text_clips.append(txt_clip)
                except Exception as e:
                    print(f"     ‚ö†Ô∏è  Skip word '{word}': {e}")
                    continue
        else:
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ word subtitles ‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á moment headlines
            print(f"   üìù ‡πÄ‡∏û‡∏¥‡πà‡∏° {len(moment_segments)} moment headlines...")
            for moment in moment_segments:
                headline = moment.get("headline", "Moment")
                viral_score = moment.get("viral_score", 0)
                
                # ‡πÉ‡∏ä‡πâ moment time ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ, ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏´‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì
                start = moment.get("start", 10.0)
                end = moment.get("end", start + 10.0)
                duration = max(0.5, end - start)
                
                # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
                if start < original_duration:
                    try:
                        txt_clip = self.create_subtitle_clip(
                            text=f"{headline}\n(Score: {viral_score}/100)",
                            start_time=start,
                            duration=min(duration, original_duration - start),
                            position=('center', 'bottom'),
                            with_animation=True
                        )
                        text_clips.append(txt_clip)
                    except Exception as e:
                        print(f"     ‚ö†Ô∏è  Skip moment: {e}")
                        continue
        
        # ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö final video
        if text_clips:
            final_video = CompositeVideoClip([video] + text_clips)
        else:
            final_video = video
        
        # ‡πÄ‡∏£‡∏ô‡πÄ‡∏î‡∏≠‡∏£‡πå
        print(f"   ‚è≥ Rendering... (‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤)")
        try:
            final_video.write_videofile(
<<<<<<< HEAD
=======
<<<<<<< HEAD
    output_name,
    fps=fps,
    codec=codec,
    audio_codec="aac",
    preset=preset
)


=======
>>>>>>> SIJN
                output_name,
                fps=fps,
                codec=codec,
                audio_codec="aac",
                preset=preset,
                temp_audiofile="temp-audio.m4a",
                remove_temp=True,
                verbose=False,
                logger=None  # ‡∏ã‡πà‡∏≠‡∏ô logging ‡∏Ç‡∏≠‡∏á MoviePy
            )
<<<<<<< HEAD
=======
>>>>>>> aa72dfb (Initial project setup: WebPedPok YouTube video analysis and content intelligence system)
>>>>>>> SIJN
            
            print(f"   ‚úÖ Render Complete!")
            return output_name
            
        except Exception as e:
            print(f"   ‚ùå Error: {e}")
            raise
        finally:
            video.close()
            if hasattr(final_video, 'close'):
                final_video.close()
    
    def render_9_16_format(
        self,
        input_video: str,
        output_name: str,
        face_tracking_data: Optional[Dict] = None,
        word_subtitles: Optional[List[Dict]] = None,
        fps: int = 30
    ) -> str:
        """‡πÄ‡∏£‡∏ô‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏ü‡∏≠‡∏£‡πå‡πÅ‡∏°‡∏ï 9:16 (Vertical TikTok-style)
        
        Args:
            input_video: ‡πÑ‡∏ü‡∏•‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï
            output_name: ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏≠‡∏≤‡∏ï‡πå‡∏û‡∏∏‡∏ï
            face_tracking_data: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• face tracking ‡∏à‡∏≤‡∏Å VisionEngine
            word_subtitles: subtitle details
            fps: Frames per second
            
        Returns:
            str: ‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏≠‡∏≤‡∏ï‡πå‡∏û‡∏∏‡∏ï
        """
        print(f"üé¨ 5. ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏ô‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ 9:16 format...")
        print(f"   Output: {output_name}")
        
        # ‡πÇ‡∏´‡∏•‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
        video = VideoFileClip(input_video)
        orig_w, orig_h = video.size
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ç‡∏ô‡∏≤‡∏î 9:16 frame
        # ‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ height ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
        target_width = int(orig_h * 9 / 16)
        target_height = orig_h
        
        if target_width > orig_w:
            # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô ‡πÉ‡∏ä‡πâ width ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
            target_width = orig_w
            target_height = int(orig_w * 16 / 9)
        
        print(f"   - Source: {orig_w}x{orig_h}")
        print(f"   - Target: {target_width}x{target_height}")
        
        # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• face tracking ‡πÉ‡∏´‡πâ crop ‡∏ï‡∏≤‡∏°‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        # ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏Ç‡πâ‡∏≤‡∏° - ‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£ crop ‡πÅ‡∏ö‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏á‡πà‡∏≤‡∏¢ (center crop)
        
        # Center crop
        crop_x = (orig_w - target_width) // 2
        crop_y = 0  # Top aligned
        
        cropped = video.crop(
            x1=crop_x,
            y1=crop_y,
            x2=crop_x + target_width,
            y2=crop_y + target_height
        )
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° subtitle ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
        text_clips = []
        if word_subtitles:
            print(f"   üìù ‡πÄ‡∏û‡∏¥‡πà‡∏° {len(word_subtitles)} subtitle...")
            for subtitle_data in word_subtitles[:100]:  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î 100 subtitle
                word = subtitle_data.get("word", "")
                start = subtitle_data.get("start", 0)
                end = subtitle_data.get("end", 0)
                duration = max(0.1, end - start)
                
                try:
                    txt_clip = self.create_subtitle_clip(
                        text=word.upper(),
                        start_time=start,
                        duration=duration,
                        position=('center', 'center')
                    )
                    text_clips.append(txt_clip)
                except:
                    continue
        
        # ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö
        if text_clips:
            final_video = CompositeVideoClip([cropped] + text_clips)
        else:
            final_video = cropped
        
        # ‡πÄ‡∏£‡∏ô‡πÄ‡∏î‡∏≠‡∏£‡πå
        print(f"   ‚è≥ Rendering...")
        try:
            final_video.write_videofile(
                output_name,
                fps=fps,
                codec="libx264",
                audio_codec="aac",
                preset="fast",
                temp_audiofile="temp-audio-vertical.m4a",
                remove_temp=True,
<<<<<<< HEAD
                verbose=False,
                logger=None
=======
<<<<<<< HEAD
                verbose=False
=======
                verbose=False,
                logger=None
>>>>>>> aa72dfb (Initial project setup: WebPedPok YouTube video analysis and content intelligence system)
>>>>>>> SIJN
            )
            
            print(f"   ‚úÖ 9:16 Render Complete!")
            return output_name
            
        except Exception as e:
            print(f"   ‚ùå Error: {e}")
            raise
        finally:
            video.close()
            if hasattr(final_video, 'close'):
                final_video.close()
